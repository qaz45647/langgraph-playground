{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "781a203f",
   "metadata": {},
   "source": [
    "# 長期記憶（Long-term Memory）\n",
    "在前面的章節中，我們使用 MemorySaver 來保存單一對話的狀態。但實際應用中，我們常需要：\n",
    "- 記住使用者的偏好（跨對話）\n",
    "- 儲存重要的事實和知識\n",
    "- 在不同對話間共享資訊\n",
    "\n",
    "LangGraph 的 Store 介面提供了長期記憶功能，讓 AI 可以跨 thread 記住資訊。\n",
    "## Store 介面概述\n",
    "Store 是一個鍵值儲存系統，與 Checkpointer 的差異：\n",
    "\n",
    "| 特性 | Checkpointer | Store |\n",
    "|------|--------------|-------|\n",
    "| 用途 | 保存對話狀態 | 儲存長期記憶 |\n",
    "| 範圍 | 單一 thread | 跨所有 thread |\n",
    "| 生命週期 | 隨對話結束 | 永久保存 |\n",
    "| 典型用途 | 對話歷史 | 使用者偏好、知識庫 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d680f6f7",
   "metadata": {},
   "source": [
    "## InMemoryStore（記憶體儲存）\n",
    "LangGraph 提供 InMemoryStore 作為最簡單的 Store 實作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ee81c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好 小明！你說：你好\n"
     ]
    }
   ],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from typing import TypedDict\n",
    "\n",
    "# 建立 Store\n",
    "store = InMemoryStore()\n",
    "\n",
    "class ChatState(TypedDict):\n",
    "    messages: list[dict]\n",
    "    user_id: str\n",
    "\n",
    "def chat_node(state: ChatState, store):\n",
    "    \"\"\"聊天節點，可以存取 store\"\"\"\n",
    "    user_id = state[\"user_id\"]\n",
    "    \n",
    "    # 從 store 讀取使用者名稱\n",
    "    user_data = store.get((\"users\", user_id), \"profile\")\n",
    "    user_name = user_data.value.get(\"name\", \"訪客\") if user_data else \"訪客\"\n",
    "    \n",
    "    user_msg = state[\"messages\"][-1][\"content\"]\n",
    "    response = f\"你好 {user_name}！你說：{user_msg}\"\n",
    "    \n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [\n",
    "            {\"role\": \"assistant\", \"content\": response}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# 建立 graph\n",
    "workflow = StateGraph(ChatState)\n",
    "workflow.add_node(\"chat\", chat_node)\n",
    "workflow.set_entry_point(\"chat\")\n",
    "workflow.add_edge(\"chat\", END)\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=checkpointer, store=store)\n",
    "\n",
    "# 先儲存使用者資料到 store\n",
    "store.put((\"users\", \"user_123\"), \"profile\", {\"name\": \"小明\", \"age\": 25})\n",
    "\n",
    "# 執行對話\n",
    "config = {\"configurable\": {\"thread_id\": \"chat_001\"}}\n",
    "result = graph.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"你好\"}],\n",
    "    \"user_id\": \"user_123\"\n",
    "}, config)\n",
    "\n",
    "print(result[\"messages\"][-1][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24400a29",
   "metadata": {},
   "source": [
    "## Store 的基本操作：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53a36e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 儲存資料\n",
    "store.put(\n",
    "    namespace=(\"users\", \"user_123\"),  # 命名空間\n",
    "    key=\"profile\",                     # 鍵\n",
    "    value={\"name\": \"小明\", \"age\": 25} # 值\n",
    ")\n",
    "\n",
    "# 讀取資料\n",
    "item = store.get((\"users\", \"user_123\"), \"profile\")\n",
    "if item:\n",
    "    data = item.value # 透過 .value 取得實際資料\n",
    "    print(data)  # {'name': '小明', 'age': 25}\n",
    "\n",
    "# 搜尋資料\n",
    "results = store.search((\"users\",))  # 回傳 Item 物件的列表\n",
    "for item in results:\n",
    "    print(item.value)  # 存取每個 Item 的值\n",
    "\n",
    "# 刪除資料\n",
    "store.delete((\"users\", \"user_123\"), \"profile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48108023",
   "metadata": {},
   "source": [
    "## Namespace 管理\n",
    "\n",
    "Namespace 用來組織和隔離不同類型的記憶，類似資料夾結構。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab24aa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用者資料:\n",
      "  profile: {'name': '小明', 'email': 'ming@example.com'}\n",
      "  settings: {'theme': 'dark', 'language': 'zh-TW'}\n",
      "\n",
      "偏好設定:\n",
      "  food: {'likes': ['咖啡', '壽司'], 'dislikes': ['香菜']}\n",
      "  hobbies: {'items': ['閱讀', '旅遊', '攝影']}\n",
      "\n",
      "所有偏好:\n",
      "  ('preferences', 'user_123'): {'likes': ['咖啡', '壽司'], 'dislikes': ['香菜']}\n",
      "  ('preferences', 'user_123'): {'items': ['閱讀', '旅遊', '攝影']}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "store = InMemoryStore()\n",
    "\n",
    "# 使用 tuple 定義階層式 namespace\n",
    "# 格式：(類型, 子類型, ID)\n",
    "\n",
    "# 1. 使用者相關資料\n",
    "store.put((\"users\", \"user_123\"), \"profile\", {\n",
    "    \"name\": \"小明\",\n",
    "    \"email\": \"ming@example.com\"\n",
    "})\n",
    "\n",
    "store.put((\"users\", \"user_123\"), \"settings\", {\n",
    "    \"theme\": \"dark\",\n",
    "    \"language\": \"zh-TW\"\n",
    "})\n",
    "\n",
    "# 2. 偏好設定\n",
    "store.put((\"preferences\", \"user_123\"), \"food\", {\n",
    "    \"likes\": [\"咖啡\", \"壽司\"],\n",
    "    \"dislikes\": [\"香菜\"]\n",
    "})\n",
    "\n",
    "store.put((\"preferences\", \"user_123\"), \"hobbies\", {\n",
    "    \"items\": [\"閱讀\", \"旅遊\", \"攝影\"]\n",
    "})\n",
    "\n",
    "# 3. 對話歷史摘要\n",
    "store.put((\"summaries\", \"user_123\"), \"2025-12\", {\n",
    "    \"topics\": [\"AI\", \"旅遊規劃\"],\n",
    "    \"interactions\": 15\n",
    "})\n",
    "\n",
    "# 4. 知識庫\n",
    "store.put((\"knowledge\", \"user_123\"), \"fact_001\", {\n",
    "    \"content\": \"喜歡喝黑咖啡\",\n",
    "    \"category\": \"preference\"\n",
    "})\n",
    "\n",
    "# 搜尋特定 namespace（回傳 Item 列表）\n",
    "user_data = store.search((\"users\", \"user_123\"))\n",
    "print(\"使用者資料:\")\n",
    "for item in user_data:\n",
    "    print(f\"  {item.key}: {item.value}\")\n",
    "\n",
    "preferences = store.search((\"preferences\", \"user_123\"))\n",
    "print(\"\\n偏好設定:\")\n",
    "for item in preferences:\n",
    "    print(f\"  {item.key}: {item.value}\")\n",
    "\n",
    "# 搜尋所有使用者的偏好\n",
    "all_preferences = store.search((\"preferences\",))\n",
    "print(\"\\n所有偏好:\")\n",
    "for item in all_preferences:\n",
    "    print(f\"  {item.namespace}: {item.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206a9375",
   "metadata": {},
   "source": [
    "## Namespace 設計："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45540429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 好的設計：清晰的階層\n",
    "(\"users\", user_id)                      # 使用者資料\n",
    "(\"preferences\", user_id)                # 使用者偏好\n",
    "(\"knowledge\", user_id)                  # 使用者知識\n",
    "(\"sessions\", user_id)                   # 對話會話\n",
    "(\"analytics\", user_id)                  # 分析資料\n",
    "\n",
    "# 不好的設計：扁平化\n",
    "(\"user_profile\",)                       # 無法區分使用者\n",
    "(\"user_123_food_preference\",)           # 難以搜尋和管理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267d8c9c",
   "metadata": {},
   "source": [
    "# 語意檢索\n",
    "\n",
    "在前面的章節中，我們使用 Store 來儲存和檢索結構化資料。但當資料量增大時，我們需要更智慧的搜尋方式——語意搜尋。它能理解查詢的「意義」，而不只是關鍵字配對。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb08cd32",
   "metadata": {},
   "source": [
    "## 整合向量資料庫\n",
    "\n",
    "### Chroma 基礎用法教學\n",
    "Chroma 是一個向量資料庫，用來儲存文字的向量（embeddings），方便做相似度搜尋。基本概念：\n",
    "\n",
    "1. 建立向量資料庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df847ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U langchain-chroma chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f1be7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"xxx\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"my_collection\",\n",
    "    embedding_function=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980c8fe1",
   "metadata": {},
   "source": [
    "- collection_name：向量庫名稱\n",
    "- embedding_function：用來將文字轉向量的函數\n",
    "\n",
    "2. 新增對話"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54ce0a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3a0cc831-102f-437b-a624-c2cdad872448',\n",
       " 'ca46a3aa-0f90-404b-b20c-6442d9e5ed49']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\"今天天氣很好\", \"我想去旅遊\"]\n",
    "metadatas = [{\"source\": \"note1\"}, {\"source\": \"note2\"}]\n",
    "vectorstore.add_texts(texts=texts, metadatas=metadatas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5504c9",
   "metadata": {},
   "source": [
    "3. 搜尋相似對話"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dfd0793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我想去旅遊 {'source': 'note2'}\n"
     ]
    }
   ],
   "source": [
    "query = \"旅遊計畫\"\n",
    "results = vectorstore.similarity_search(query, k=1)\n",
    "for r in results:\n",
    "    print(r.page_content, r.metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae8c0ce",
   "metadata": {},
   "source": [
    "- similarity_search(query, k=3, filter=...)：查詢最相似的 k 筆資料，可加條件篩選\n",
    "\n",
    "- add_texts(texts, metadatas)：新增文本及對應 metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fa922e",
   "metadata": {},
   "source": [
    "## 對話歷史語意搜尋(結合短期+長期記憶)\n",
    "\n",
    "建立一個具備長期記憶能力的對話系統，讓 AI 助理能記住過往對話，並在未來的對話中智慧地召回相關記憶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3cc3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "使用者輸入\n",
    "   ↓\n",
    "search_history_node -> 從 Chroma 找「摘要記憶」\n",
    "   ↓\n",
    "chat_with_history_node -> LLM 結合長期記憶與近期對話\n",
    "   ↓\n",
    "archive_node -> 產生 summary 並存入 Chroma / InMemoryStore\n",
    "   ↓\n",
    "END\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131b8800",
   "metadata": {},
   "source": [
    "### 步驟 1: 建立對話歸檔類別\n",
    "\n",
    "首先建立 ConversationArchive 類別來管理所有記憶相關的操作:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa846768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"xxx\"\n",
    "\n",
    "class ConversationArchive:\n",
    "    def __init__(self):\n",
    "        # 初始化 OpenAI 嵌入模型\n",
    "        self.embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "        \n",
    "        # 建立 Chroma 向量資料庫\n",
    "        self.vectorstore = Chroma(\n",
    "            collection_name=\"conversation_archive\",\n",
    "            embedding_function=self.embeddings\n",
    "        )\n",
    "        \n",
    "        # 建立記憶體儲存\n",
    "        self.store = InMemoryStore()\n",
    "        \n",
    "        # 初始化 LLM 用於生成摘要\n",
    "        self.llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dfb3bc",
   "metadata": {},
   "source": [
    "### 步驟 2: 對話摘要生成\n",
    "\n",
    "將多輪對話濃縮成一句有意義的摘要:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5571ed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(self, messages: list[dict]) -> str:\n",
    "    \"\"\"\n",
    "    將對話濃縮成摘要,重點放在使用者意圖和偏好\n",
    "    \"\"\"\n",
    "    # 將訊息格式化為對話文本\n",
    "    conversation = \"\\n\".join(f\"{m['role']}: {m['content']}\" for m in messages)\n",
    "    \n",
    "    # 設計提示詞,引導 LLM 生成高品質摘要\n",
    "    prompt = f\"\"\"\n",
    "    請將以下對話濃縮成一句「可作為長期記憶的摘要」,\n",
    "    重點放在使用者的意圖、偏好或討論主題:\n",
    "    \n",
    "    {conversation}\n",
    "    \n",
    "    摘要:\n",
    "    \"\"\"\n",
    "    \n",
    "    return self.llm.invoke(prompt).content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a19ac2d",
   "metadata": {},
   "source": [
    "### 步驟 3: 歸檔對話到雙層儲存\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8b59d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def archive_conversation(self, user_id: str, thread_id: str, messages: list):\n",
    "    # 生成摘要\n",
    "    summary = self.generate_summary(messages)\n",
    "    \n",
    "    # 提取主題標籤\n",
    "    topics = self._extract_topics(summary)\n",
    "    \n",
    "    # 向量庫只存摘要(用於搜尋)\n",
    "    self.vectorstore.add_texts(\n",
    "        texts=[summary],\n",
    "        metadatas=[{\n",
    "            \"user_id\": user_id,\n",
    "            \"thread_id\": thread_id,\n",
    "            \"topics\": \",\".join(topics),\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }]\n",
    "    )\n",
    "    \n",
    "    # Store 存完整資料(用於詳細檢索)\n",
    "    self.store.put((\"archives\", user_id), thread_id, {\n",
    "        \"summary\": summary,\n",
    "        \"topics\": topics,\n",
    "        \"messages\": messages,\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    })\n",
    "\n",
    "def _extract_topics(self, text: str) -> list[str]:\n",
    "    \"\"\"簡單的關鍵字提取(實際應用可使用 NLP 工具)\"\"\"\n",
    "    keywords = [\"旅遊\", \"美食\", \"工作\", \"學習\", \"運動\", \"電影\"]\n",
    "    return [kw for kw in keywords if kw in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5335f81f",
   "metadata": {},
   "source": [
    "**雙層儲存策略**\n",
    "\n",
    "- Chroma 儲存摘要向量 + metadata ,支援語義搜尋\n",
    "- InMemoryStore 儲存完整對話,用於獲取詳細資訊\n",
    "- 兩者透過 thread_id 關聯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb42cb8",
   "metadata": {},
   "source": [
    "### 步驟 4: 記憶搜尋\n",
    "使用向量相似度搜尋找出相關的歷史對話:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f75d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_similar_conversations(self, query: str, user_id: str, k: int = 3):\n",
    "    \"\"\"\n",
    "    使用 Chroma 向量搜尋,召回最相關的長期記憶\n",
    "    \n",
    "    參數:\n",
    "        query: 使用者的當前訊息\n",
    "        user_id: 使用者 ID(確保只搜尋該使用者的記憶)\n",
    "        k: 返回最相關的 k 條記憶\n",
    "    \"\"\"\n",
    "    # 向量搜尋\n",
    "    results = self.vectorstore.similarity_search(\n",
    "        query, \n",
    "        k=k, \n",
    "        filter={\"user_id\": user_id}\n",
    "    )\n",
    "    \n",
    "    memories = []\n",
    "    for doc in results:\n",
    "        thread_id = doc.metadata[\"thread_id\"]\n",
    "        \n",
    "        # 從 Store 獲取完整資訊\n",
    "        archived = self.store.get((\"archives\", user_id), thread_id)\n",
    "        \n",
    "        if archived:\n",
    "            memories.append({\n",
    "                \"thread_id\": thread_id,\n",
    "                \"topics\": archived.value[\"topics\"],\n",
    "                \"summary\": archived.value[\"summary\"]\n",
    "            })\n",
    "    \n",
    "    return memories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcba2ad",
   "metadata": {},
   "source": [
    "**搜尋流程:**\n",
    "\n",
    "1. 將使用者查詢轉換為向量\n",
    "2. 在 Chroma 中找出最相似的摘要\n",
    "3. 使用 thread_id 從 Store 獲取完整資訊\n",
    "4. 返回結構化的記憶列表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af7730d",
   "metadata": {},
   "source": [
    "### 步驟 5: 建立 LangGraph 工作流程\n",
    "\n",
    "定義狀態和節點:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d11025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from typing import TypedDict, Annotated\n",
    "from operator import add\n",
    "\n",
    "archive = ConversationArchive()\n",
    "\n",
    "# 定義狀態結構\n",
    "class ArchiveState(TypedDict):\n",
    "    messages: Annotated[list[dict], add]  # 對話訊息(可累加)\n",
    "    user_id: str                           # 使用者 ID\n",
    "    thread_id: str                         # 對話執行緒 ID\n",
    "    similar_conversations: list[dict]      # 召回的相關記憶\n",
    "    archived: bool                         # 是否已歸檔\n",
    "\n",
    "# 節點 1: 搜尋歷史記憶\n",
    "def search_history_node(state: ArchiveState):\n",
    "    query = state[\"messages\"][-1][\"content\"]  # 使用最新訊息作為查詢\n",
    "    user_id = state[\"user_id\"]\n",
    "    \n",
    "    similar = archive.search_similar_conversations(query, user_id, k=2)\n",
    "    \n",
    "    return {\"similar_conversations\": similar}\n",
    "\n",
    "# 節點 2: 基於記憶的對話生成\n",
    "def chat_with_history_node(state: ArchiveState):\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "    \n",
    "    user_msg = state[\"messages\"][-1][\"content\"]\n",
    "    memories = state.get(\"similar_conversations\", [])\n",
    "    \n",
    "    # 格式化長期記憶\n",
    "    memory_text = \"\\n\".join(\n",
    "        f\"- {m['summary']}\" for m in memories\n",
    "    ) if memories else \"（目前沒有相關的長期記憶）\"\n",
    "    \n",
    "    # 格式化近期對話\n",
    "    recent_messages = state[\"messages\"][-6:]  # 只使用最近 6 則訊息\n",
    "    dialogue_text = \"\\n\".join(\n",
    "        f\"{m['role']}: {m['content']}\" for m in recent_messages\n",
    "    )\n",
    "    \n",
    "    # 設計系統提示詞\n",
    "    system_prompt = f\"\"\"\n",
    "    你是一位有「長期記憶能力」的對話助理。\n",
    "    \n",
    "    【長期記憶(來自過往對話摘要)】\n",
    "    {memory_text}\n",
    "    \n",
    "    【近期對話】\n",
    "    {dialogue_text}\n",
    "    \n",
    "    請根據「長期記憶 + 近期對話」,自然地回應使用者。\n",
    "    - 不要逐字重複摘要\n",
    "    - 回答要具體、有建議\n",
    "    - 如果是旅遊問題,可以主動提供選項\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_msg}\n",
    "    ])\n",
    "    \n",
    "    return {\"messages\": [{\"role\": \"assistant\", \"content\": response.content}]}\n",
    "\n",
    "# 節點 3: 歸檔對話\n",
    "def archive_node(state: ArchiveState):\n",
    "    # 只有在未歸檔且訊息足夠多時才歸檔\n",
    "    if not state[\"archived\"] and len(state[\"messages\"]) >= 4:\n",
    "        archive.archive_conversation(\n",
    "            state[\"user_id\"], \n",
    "            state[\"thread_id\"], \n",
    "            state[\"messages\"]\n",
    "        )\n",
    "        return {\"archived\": True}\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85479b85",
   "metadata": {},
   "source": [
    "**節點設計說明:**\n",
    "\n",
    "1. search_history_node: 在每次對話開始時搜尋相關記憶\n",
    "2. chat_with_history_node: 結合長期記憶和近期對話生成回應\n",
    "3. archive_node: 在對話結束時歸檔"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d64d44",
   "metadata": {},
   "source": [
    "### 步驟 6: 組裝工作流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a2ba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立工作流程圖\n",
    "workflow = StateGraph(ArchiveState)\n",
    "\n",
    "# 添加節點\n",
    "workflow.add_node(\"search_history\", search_history_node)\n",
    "workflow.add_node(\"chat\", chat_with_history_node)\n",
    "workflow.add_node(\"archive\", archive_node)\n",
    "\n",
    "# 定義節點之間的連接\n",
    "workflow.set_entry_point(\"search_history\")\n",
    "workflow.add_edge(\"search_history\", \"chat\")\n",
    "workflow.add_edge(\"chat\", \"archive\")\n",
    "workflow.add_edge(\"archive\", END)\n",
    "\n",
    "# 編譯工作流程,加入 checkpointer 以支援狀態持久化\n",
    "graph = workflow.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93987fa4",
   "metadata": {},
   "source": [
    "### 步驟 7: 實際使用範例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e54d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化歸檔系統\n",
    "archive = ConversationArchive()\n",
    "\n",
    "user_id = \"user_004\"\n",
    "\n",
    "# === 第一次對話 ===\n",
    "thread_id = \"thread_001\"\n",
    "state = {\n",
    "    \"messages\": [], \n",
    "    \"user_id\": user_id, \n",
    "    \"thread_id\": thread_id, \n",
    "    \"similar_conversations\": [], \n",
    "    \"archived\": False\n",
    "}\n",
    "\n",
    "# 模擬多輪對話\n",
    "messages = [\n",
    "    \"我想去日本旅遊\",\n",
    "    \"我特別想去京都看櫻花\"\n",
    "]\n",
    "\n",
    "for msg in messages:\n",
    "    state = graph.invoke(\n",
    "        {**state, \"messages\": [{\"role\": \"user\", \"content\": msg}]},\n",
    "        config={\"configurable\": {\"thread_id\": thread_id}}\n",
    "    )\n",
    "    print(f\"使用者: {msg}\")\n",
    "    print(f\"助理: {state['messages'][-1]['content']}\\n\")\n",
    "\n",
    "# === 第二次對話(新的 thread,但會召回記憶) ===\n",
    "thread_id = \"thread_002\"\n",
    "state = {\n",
    "    \"messages\": [], \n",
    "    \"user_id\": user_id, \n",
    "    \"thread_id\": thread_id, \n",
    "    \"similar_conversations\": [], \n",
    "    \"archived\": False\n",
    "}\n",
    "\n",
    "msg = \"你覺得春天去哪裡旅遊好?\"\n",
    "result = graph.invoke(\n",
    "    {**state, \"messages\": [{\"role\": \"user\", \"content\": msg}]},\n",
    "    config={\"configurable\": {\"thread_id\": thread_id}}\n",
    ")\n",
    "\n",
    "print(f\"使用者: {msg}\")\n",
    "print(f\"助理: {result['messages'][-1]['content']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bc1fa6",
   "metadata": {},
   "source": [
    "1. 搜尋到之前關於「日本京都櫻花」的對話\n",
    "2. 在回應中自然地連結到使用者的偏好\n",
    "3. 可能建議:「根據你之前提到喜歡賞櫻,春天去京都是最佳選擇...」\n",
    "\n",
    "### 完整程式碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770bbe70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MyPc\\AppData\\Local\\Temp\\ipykernel_3552\\148703571.py:29: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  self.llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "使用者: 你覺得春天去哪裡旅遊好？\n",
      "助理: 春天是一個非常適合旅遊的季節，尤其是在日本，特別是京都，賞櫻花的景色絕對讓人難以忘懷。除了京都，你也可以考慮東京的上野公園，或者大阪的櫻花名所如大阪城公園。如果你想要更自然的景色，可以考慮前往富士山周邊的地方，春天的富士山非常迷人。你對哪些地方特別感興趣呢？\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from typing import TypedDict, Annotated\n",
    "from operator import add\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"xxx\"\n",
    "\n",
    "# 對話存檔與長期記憶管理\n",
    "class ConversationArchive:\n",
    "    def __init__(self):\n",
    "        # 使用 OpenAI Embeddings\n",
    "        self.embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "        # 使用 Chroma 建立向量資料庫\n",
    "        self.vectorstore = Chroma(\n",
    "            collection_name=\"conversation_archive\",\n",
    "            embedding_function=self.embeddings\n",
    "        )\n",
    "        # InMemoryStore 用來存完整訊息資料\n",
    "        self.store = InMemoryStore()\n",
    "        # LLM 用於摘要\n",
    "        self.llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    def generate_summary(self, messages: list[dict]) -> str:\n",
    "        \"\"\"\n",
    "        將多則對話濃縮成一句摘要，用於長期記憶。\n",
    "        \"\"\"\n",
    "        conversation = \"\\n\".join(f\"{m['role']}: {m['content']}\" for m in messages)\n",
    "        prompt = f\"\"\"\n",
    "        請將以下對話濃縮成一句「可作為長期記憶的摘要」，\n",
    "        重點放在使用者的意圖、偏好或討論主題：\n",
    "\n",
    "        {conversation}\n",
    "\n",
    "        摘要：\n",
    "        \"\"\"\n",
    "        return self.llm.invoke(prompt).content.strip()\n",
    "\n",
    "    def archive_conversation(self, user_id: str, thread_id: str, messages: list):\n",
    "        summary = self.generate_summary(messages)\n",
    "        topics = self._extract_topics(summary)\n",
    "\n",
    "        # 向量庫只存 summary\n",
    "        self.vectorstore.add_texts(\n",
    "            texts=[summary],\n",
    "            metadatas=[{\n",
    "                \"user_id\": user_id,\n",
    "                \"thread_id\": thread_id,\n",
    "                \"topics\": \",\".join(topics),\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }]\n",
    "        )\n",
    "\n",
    "        # Store 存完整資料\n",
    "        self.store.put((\"archives\", user_id), thread_id, {\n",
    "            \"summary\": summary,\n",
    "            \"topics\": topics,\n",
    "            \"messages\": messages,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        })\n",
    "\n",
    "    def search_similar_conversations(self, query: str, user_id: str, k: int = 3):\n",
    "        \"\"\"\n",
    "        使用 Chroma 向量搜尋，召回最相關的長期記憶摘要\n",
    "        \"\"\"\n",
    "        results = self.vectorstore.similarity_search(query, k=k, filter={\"user_id\": user_id})\n",
    "        memories = []\n",
    "        for doc in results:\n",
    "            thread_id = doc.metadata[\"thread_id\"]\n",
    "            archived = self.store.get((\"archives\", user_id), thread_id)\n",
    "            if archived:\n",
    "                memories.append({\n",
    "                    \"thread_id\": thread_id,\n",
    "                    \"topics\": archived.value[\"topics\"],\n",
    "                    \"summary\": archived.value[\"summary\"]\n",
    "                })\n",
    "        return memories\n",
    "\n",
    "    def _extract_topics(self, text: str) -> list[str]:\n",
    "        keywords = [\"旅遊\", \"美食\", \"工作\", \"學習\", \"運動\", \"電影\"]\n",
    "        return [kw for kw in keywords if kw in text]\n",
    "\n",
    "archive = ConversationArchive()\n",
    "\n",
    "# Workflow State\n",
    "class ArchiveState(TypedDict):\n",
    "    messages: Annotated[list[dict], add]\n",
    "    user_id: str\n",
    "    thread_id: str\n",
    "    similar_conversations: list[dict]\n",
    "    archived: bool  \n",
    "\n",
    "# Node\n",
    "def search_history_node(state: ArchiveState):\n",
    "    query = state[\"messages\"][-1][\"content\"]\n",
    "    user_id = state[\"user_id\"]\n",
    "    similar = archive.search_similar_conversations(query, user_id, k=2)\n",
    "    return {\"similar_conversations\": similar}\n",
    "\n",
    "def chat_with_history_node(state: ArchiveState):\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "    user_msg = state[\"messages\"][-1][\"content\"]\n",
    "    memories = state.get(\"similar_conversations\", [])\n",
    "\n",
    "    memory_text = \"\\n\".join(f\"- {m['summary']}\" for m in memories) if memories else \"（目前沒有相關的長期記憶）\"\n",
    "    recent_messages = state[\"messages\"][-6:]\n",
    "    dialogue_text = \"\\n\".join(f\"{m['role']}: {m['content']}\" for m in recent_messages)\n",
    "\n",
    "    system_prompt = f\"\"\"\n",
    "    你是一位有「長期記憶能力」的對話助理。\n",
    "\n",
    "    【長期記憶（來自過往對話摘要）】\n",
    "    {memory_text}\n",
    "\n",
    "    【近期對話】\n",
    "    {dialogue_text}\n",
    "\n",
    "    請根據「長期記憶 + 近期對話」，自然地回應使用者。\n",
    "    - 不要逐字重複摘要\n",
    "    - 回答要具體、有建議\n",
    "    - 如果是旅遊問題，可以主動提供選項\n",
    "    \"\"\"\n",
    "    response = llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_msg}\n",
    "    ])\n",
    "    return {\"messages\": [{\"role\": \"assistant\", \"content\": response.content}]}\n",
    "\n",
    "def archive_node(state: ArchiveState):\n",
    "    if not state[\"archived\"] and len(state[\"messages\"]) >= 4:\n",
    "        archive.archive_conversation(state[\"user_id\"], state[\"thread_id\"], state[\"messages\"])\n",
    "        return {\"archived\": True}\n",
    "    return {}\n",
    "\n",
    "# Workflow 建立\n",
    "workflow = StateGraph(ArchiveState)\n",
    "workflow.add_node(\"search_history\", search_history_node)\n",
    "workflow.add_node(\"chat\", chat_with_history_node)\n",
    "workflow.add_node(\"archive\", archive_node)\n",
    "workflow.set_entry_point(\"search_history\")\n",
    "workflow.add_edge(\"search_history\", \"chat\")\n",
    "workflow.add_edge(\"chat\", \"archive\")\n",
    "workflow.add_edge(\"archive\", END)\n",
    "graph = workflow.compile(checkpointer=MemorySaver())\n",
    "\n",
    "# 範例對話流程\n",
    "user_id = \"user_004\"\n",
    "\n",
    "# 第一次對話\n",
    "thread_id = \"thread_001\"\n",
    "state = {\"messages\": [], \"user_id\": user_id, \"thread_id\": thread_id, \"similar_conversations\": [], \"archived\": False}\n",
    "msgs = [\"我想去日本旅遊\", \"我特別想去京都看櫻花\"]\n",
    "for msg in msgs:\n",
    "    state = graph.invoke({**state, \"messages\": [{\"role\": \"user\", \"content\": msg}]},\n",
    "                         config={\"configurable\": {\"thread_id\": thread_id}})\n",
    "\n",
    "# 第二次對話（召回長期記憶）\n",
    "thread_id = \"thread_002\"\n",
    "state = {\"messages\": [], \"user_id\": user_id, \"thread_id\": thread_id, \"similar_conversations\": [], \"archived\": False}\n",
    "msg = \"你覺得春天去哪裡旅遊好？\"\n",
    "result = graph.invoke({**state, \"messages\": [{\"role\": \"user\", \"content\": msg}]},\n",
    "                      config={\"configurable\": {\"thread_id\": thread_id}})\n",
    "\n",
    "print(f\"\\n使用者: {msg}\")\n",
    "print(f\"助理: {result['messages'][-1]['content']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972983fb",
   "metadata": {},
   "source": [
    "### to be continued"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
